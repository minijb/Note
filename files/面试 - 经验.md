---
tags:
  - 面试
---

## C sharp
### 1. class 和 struct 的区别

1. struct 位值类型， class 位引用类型
2. struct 默认 publc ， class 默认 private
3. 继承 struct 默认是 private ， class 默认是public
4. class 可以使用模板， struct 不可以

### 2. C# GC + Unity GC

#TODO

### 3. 接口和抽象类的区别

1. 接口不是类，不能实例化，抽象类可以间接实例化
2. 接口完全抽象，抽象类位部分抽象
3. 接口可以多继承，抽象类是单继承

### 3. 集合类型

#### 3.1  一些接口

**IList**

1. 是一个泛型接口
2. 派生自 ICollection 接口
3. 允许访问插入移除元素等。

```c#
public interface IList<T> : ICollection<T>, IEnumerable<T>, IEnumerable
{
  T this[int index] { get; set; }
  int IndexOf(T item);
  void Insert(int index, T item);
  void RemoveAt(int index);
}
```

**IEnumerable**  枚举器

```c#
  [TypeDependency("System.SZArrayHelper")]
  public interface IEnumerable<out T> : IEnumerable
  {
    // 摘要:
    //   返回一个循环访问集合的枚举器。
    //
    // 返回结果:
    //   可用于循环访问集合的 System.Collections.Generic.IEnumerator<T>。
    IEnumerator<T> GetEnumerator();
  }
```


**ICollection** 集合 

主要功能就是 

1. Count
2. `void CopyTo(Array array, int index);` 用于复制

[[ICollection]]

#### 3.2 常用集合

1. Array ： 固定长度的数组，类型必须相同，无法确定当前的实际长度
2. ArrayList ： 没有泛型的 List 数组，知道实际长度，但是**ArrayList不是类型安全的**。**需要装箱和拆线**， 实现 `IList`
3. List ： ArrayList 的泛型版本，类型安全，**实现IList**
4. ListedList ： 基于链表的集合
5. Dictionary 底层时 哈希表， 最小单位 ： Entry（hash, next, key, value）
6. HashSet
7. Vector 线程安全的动态数组，支持泛型
8. 

- List 底层 是一个数组。具体扩容方式为增加一倍（只有在容量不够的时候才会口容）

### 4. 如何拷贝

#### 4.1 浅拷贝

```c++
class Person
{
    public string Name { get; set; } // 值类型属性，字符串实际上是引用类型，但在此处作为不可变对象讨论
    public Car CarOwned { get; set; } // 引用类型属性
}

class Car
{
    public string Brand { get; set; }
}

// 创建原始对象
var originalPerson = new Person { Name = "Alice", CarOwned = new Car { Brand = "Toyota" } };
var shallowCopyPerson = originalPerson.MemberwiseClone(); // 使用默认的浅拷贝方法

// 修改浅拷贝后的引用类型字段
shallowCopyPerson.CarOwned.Brand = "Ford";

// 输出结果会显示两个对象的CarOwned.Brand都为"Frod"
Console.WriteLine(originalPerson.CarOwned.Brand); // 输出 "Ford"
Console.WriteLine(shallowCopyPerson.CarOwned.Brand); // 输出 "Ford"

```

#### 4.2 深拷贝

```c++
class Person
{
    public string Name { get; set; }
    public Car CarOwned { get; set; }

    // 自定义深拷贝方法
    public Person DeepCopy()
    {
        var copy = (Person)this.MemberwiseClone();
        if (this.CarOwned != null)
            copy.CarOwned = new Car { Brand = this.CarOwned.Brand }; // 深拷贝Car对象

        return copy;
    }
}

class Car
{
    public string Brand { get; set; }
}

// 创建原始对象
var originalPerson = new Person { Name = "Alice", CarOwned = new Car { Brand = "Toyota" } };
var deepCopyPerson = originalPerson.DeepCopy();

// 修改深拷贝后的引用类型字段
deepCopyPerson.CarOwned.Brand = "Ford";

// 输出结果会显示原对象的CarOwned.Brand仍然是"Toyota"
Console.WriteLine(originalPerson.CarOwned.Brand); // 输出 "Toyota"
Console.WriteLine(deepCopyPerson.CarOwned.Brand); // 输出 "Ford"

```

## C++

### 1. Vector 存储原理

1. 底层是数组
2. 动态扩展

### 2. 虚函数和纯虚函数 --- 抽象类

虚函数 ： virtual
纯虚函数 : `virtual void foo() = 0;`  没有具体实现，只提供函数原型，目的是位了实现接口的定义。

抽象类 ： 如果类中至少有一个函数被声明为纯虚函数，则这个类就是抽象类。 不可以实例化一个抽象类。

底层原理： 纯虚函数和虚函数一样。 只是由于纯虚函数没有具体实现，因此不能直接调用纯虚函数，只能通过派生类来实现调用。

### 3. 深拷贝，浅拷贝

浅拷贝就是成员之间简单的废止， 深拷贝需要开辟另一个块内存。

### 4. 指针常量 和 常量指针

指针常量 : `int * const p = &a`  本身是一个常量， 
常量指针 : `const int * p`  指向一个 常量

### 5. 智能指针

- unique_ptr：独占式指针，同一时刻只能有一个指针指向同一个对象
- shared_ptr：共享式指针，同一时刻可以有多个指针指向同一个对象
- weak_ptr：用来解决shared_ptr相互引用导致的死锁问题

**unique_ptr  不能 进行拷贝**

#### 5.1 shared_ptr

**初始化**

```c++
shared_ptr<int> pi; // 指向int的空智能指针，pi==nullptr
shared_ptr<int> pi(new int(100)); // pi指向一个值为100的int型数据
shared_ptr<int> p1 = new int(1024); // 错误

// 因此 如果返回值位 share_ptr 不能使用隐式转换
shared_ptr<int> clone(int p) {
	return new int(p); // 错误
}
```

**make_share 函数**

最安全的分配和使用动态内存， 

```c++
shared_ptr<int> p3 = make_shared<int>(42);
```

**拷贝构造/赋值**

```c++
auto p = make_shared<int>(42); // p指向的对象只有p一个引用者
auto q(p); // p和q指向相同对象，此对象有两个引用者
```

无论何时我们拷贝一个 shared_ptr，计数器都会递增例如，当用一个 shared_ptr 初始化另一个 shared_ptr，或将它作为参数传递给一个函数以及作为函数的返回值时，它所关联的计数器就会递增。

当我们给 shared_ptr 赋予一个新值或是 shared_ptr 被销毁（例如一个局部的 shared_ptr 离开其作用域）时，计数器就会递减。

```c++
auto r = make_shared<int>(42); // r指向的int只有一个引用者
r = q;
// 给r赋值，令它指向另一个地址
// 递增q指向的对象的引用计数
// 递减r原来指向的对象的引用计数
// r原来指向的对象已没有引用者，会自动释放

```

在上面代码中，我们分配了一个 int，将其指针保存在 r 中。接下来，我们将一个新值赋予 r。在此情况下，r 是唯一指向此 int 的 shared_ptr，在把 q 赋给 r 的过程中，此 int 被自动释放。

**移动构造/赋值**

```c++
int main()
{
    shared_ptr<int> sp1(new int(180)); // 强引用计数从0变1
    
    shared_ptr<int> sp2(std::move(sp1)); // 移动构造一个新的智能指针对象sp2，sp1变成空，sp2指向该内存，强引用计数仍为1

	return 0;
}


int main()
{
    shared_ptr<int> sp1(new int(180)); // 强引用计数从0变1

    shared_ptr<int> sp2;

    sp2 = std::move(sp1); // 移动赋值，sp1变成空，sp2指向该内存，强引用计数仍为1

	return 0;
}
```

**自动销毁**

当指向一个对象的最后一个 shared_ptr 被销毁时，shared_ptr 类会自动销毁此对象。它是通过析构函数完成销毁工作的。

类似于构造函数，每个类都有一个析构函数。就像构造函数控制初始化一样，析构函数控制此类型的对象销毁时做什么操作。析构函数一般用来释放对象所分配的资源。例如，string 的构造函数会分配内存来保存构成 string 的字符，string 的析构函数就负责释放这些内存。类似的，vector 的若干操作都会分配内存来保存其元素，vector 的析构函数就负责销毁这些元素，并释放它们所占用的内存。
shared_ptr 的析构函数会递减它所指向的对象的引用计数。如果引用计数变为 0 00，shared_ptr 的析构函数就会销毁对象，并释放它占用的内存。


**自动释放**

```c++
// create()函数返回一个shared_ptr，指向一个动态分配的对象
shared_ptr<int> create(int value)
{
    return make_shared<int>(value); // shared_ptr负责释放内存
}

void fun(int value)
{
    shared_ptr<int> p = create(value); // p离开了作用域，它指向的内存会被自动释放掉
    return;
}

int main()
{
    fun(12);
    return 0;
}
```

在下面代码中，fun() 函数将 create() 函数返回的 shared_ptr 保存在局部变量 p 中，由于 p 是 fun() 函数的局部变量，在 fun() 函数结束时它将被销毁。当 p 被销毁时，将递减其引用计数并检查它是否为 0 。在此例中，p 是唯一引用 create() 函数返回的内存的对象。由于 p 将要销毁，p 指向的这个对象也会被销毁，所占用的内存会被释放。

#### 5.2 weak_ptr

shared_ptr中有一个成员时，弱引用计数。往weak_ptr被赋值时，弱引用计数自增1

- 用来解决悬空指针，通过std::shared_ptr管理数据并将std::weak_ptr提供给数据用户，用户可以通过expired()或者lock()来检测数据的有效性
- 打破shared_ptr相互引用导致死锁的问题。方法：将任意一个改为weak_ptr

**检测指针是否被销毁**

expired()：

- 判断强引用计数是否为0
- 如果返回true，那么被观测的对象(也就是shared_ptr管理的资源)已经不存在了

**将 weak_ptr 转换为 shared_ptr**

用lock():

- 如果expired()为true，返回一个空shared_ptr，否则返回非空shared_ptr。


#### 5.3 lambda 捕获 unique_ptr

![图片](https://i-blog.csdnimg.cn/blog_migrate/967daeb698cd33ccdb7ed663a5eba0d4.png)

1. 使用引用 来捕获 unique_ptr  --- 加入 mutable 关键字就可以修改 const

```c++
  auto str = std::make_unique<std::string>("my string");
    auto lambda = [capturedStr = std::move(str)]{
        std::cout << *capturedStr.get() << std::endl;
    };
    lambda();
```

### 6. 完美转发

![[面试 - c++#移动语义 + 完美转发]]


### 7. 编译和链接的区别

1. 编译 ： 将代码翻译为汇编代码
2. 汇编 ： 将汇编代码转变为二进制
3. 链接 ： 由链接程序将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个完整的载入模型。链接主要解决模块间的相互引用问题。分为地址和空间分配，符号解析和重定位几个步骤。

(1)第一步：由于每个.o文件都有都有自己的代码段、bss段，堆，栈等，所以链接器首先将多个.o 文件相应的段进行合并，建立映射关系并且去合并符号表。进行符号解析，符号解析完成后就是给符号分配虚拟地址。

(2)第二步：将分配好的虚拟地址与符号表中的定义的符号一一对应起来，使其成为正确的地址，使代码段的指令可以根据符号的地址执行相应的操作，最后由链接器生成可执行文件。

**静态链接** ： 静态链接就是在链接阶段把.o文件中所依赖的静态库链接到一起，最终生成的可执行文件当中包含lib中的函数
**动态链接** ： 当链接器发现某个符号的定义在DLL中，那么它不会把这个符号的定义加入到最终生成的可执行文件中，而是将该符号与其对应的库名称记录下来（保存在可执行文件中）。当程序开始运行时，操作系统会及时地将剩余的链接工作做完以保证程序的正常运行

 i. 动态链接库的优点：（1）更加节省内存；（2）DLL文件与EXE文件独立，只要输出接口不变，更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了可维护性和可扩展性。

ii. 动态链接库的缺点： 使用动态链接库的应用程序不是自完备的，它依赖的DLL模块也要存在，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息。

iii. 静态链接库的优点： (1) 代码装载速度快，执行速度略比动态链接库快； (2) 只需保证在开发者的计算机中有正确的.LIB文件，在以二进制形式发布程序时不需考虑在用户的计算机上.LIB文件是否存在及版本问题，可避免DLL地狱等问题。

iv. 静态链接库的缺点： 使用静态链接生成的可执行文件体积较大，包含相同的公共代码，造成浪费。

### 8. 如何拷贝

对于值类型 直接 进行拷贝， 对于指针，需要进行深拷贝

```c++
class MyString {
private:
    char* buffer;
public:
    // 构造函数
    MyString(const char* initialInput) {
        if (initialInput != nullptr) {
            buffer = new char[strlen(initialInput) + 1];
            strcpy(buffer, initialInput);
        } else {
            buffer = nullptr;
        }
    }
    
    // 拷贝构造函数（浅拷贝）
    MyString(const MyString& other) {
        buffer = other.buffer; // 浅拷贝，只复制指针的值
    }
    
    // 拷贝构造函数（深拷贝）
    MyString(const MyString& other) {
        if (other.buffer != nullptr) {
            buffer = new char[strlen(other.buffer) + 1];
            strcpy(buffer, other.buffer);
        } else {
            buffer = nullptr;
        }
    }

```

### 9. 内存对齐

**三大规则**
- 第一个成员的偏移量为0 
- 其他成员要对齐到**对齐数倍数**的地址  对齐数 = 默认的对齐数与当前成员的大小种的较小值。
- 结构体总大小为最大对齐数的整数倍

![[面试准备#结构体对齐]]
## 操作系统

### 1. 进程调度算法

**先来先服务（FCFS）调度算法**
FCFS是一种最简单的调度算法，它既可以用于作业的调度，又可以用于进程调度。在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将他们调入内存，分配必要的资源，创建进程并放入就绪队列。
在进程调度中，FCFS调度算法每次从就绪队列中选择最先进入该队列的进程，将处理机分噢诶给它，使之投入运行，直到完成或尹某种原因而阻塞时才释放处理机。
FCFS属于不可剥夺（抢占）算法。从表面上看，它对所有作业都是公平的，但是如果有一个长作业先到达系统，就会使后面许多短作业等待很长时间，因此这种方法肯定不能作为分时系统和实时系统的调度方法，但是它常被结合在其他调度策略使用。比如在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按FCFS原则处理。
· 特点分析：算法简单，但是效率低下；对长作业较为有利，对短作业不利；利于CPU繁忙型作业，不利于I/O繁忙型作业。

**短作业优先（SJF）调度算法**
短作业（进程）优先调度算法是指对短作业（进程）优先调度算法。短作业优先调度算法从后备队列中选择一个或若干估计运行时间最短的作业，将它们调入内存运行；短进程优先（SPF）调度算法是从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即指向，直到完成或发生某时间而阻塞时，才释放处理机。
但是这种算法有着不容忽视的缺点：
①该算法对长作业不利，SJF中长作业的周转时间会增加。更糟的是，若一旦有长作业进入系统的后备队列，由于调度程序总是优先调度那些短作业（即使是后来的短作业也会被优先安排给处理机），导致长作业长期不被调度，饿死在后备队列中。
②完全没有考虑作业的紧迫程度，因而不能保证紧迫的作业会被及时处理。
③由于作业的长短只是根据用户所提供的预估的执行时间而定的，而用户又可能会有意无意地缩短其作业的估计运行时间，使得算法不一定能真正做到短作业优先调度。
但这算法的优点也显而易见：平均等待时间、平均周转时间最少。

**最短剩余时间优先**

**优先级调度算法**
又称优先权调度算法，它既可以用于作业调度，又可用于进程调度。该算法的优先级用于描述作业运行的紧迫程度。
在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最该的一个或几个作业，将他们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，并分配处理机，运行。
根据新的更高的优先级进程能否抢占正在执行的进程，可将该调度算法分为如下两种：
①非剥夺（抢占）式优先级调度算法：当一个进程正在处理机上运行时，即使有某个更在重要或者紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于自身的原因而主动让出处理机时（任务完成或等待），才把处理机分配给更重要或紧迫的进程。
②剥夺式优先级调度算法：当一个进程正在处理机上运行，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。
而根据进程创建后其优先级是否可以改变，可以将进程优先级分为一下两种：
①静态优先级：优先级是在创建进程时确定的，并且进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。
②动态优先级：在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据有进程占有CPU的时间的长短、就绪进程等待CPU时间的长短。
一般来说，进程优先级可以参考一下原则：
①系统进程>用户进程。
②交互型进程>非交互型进程（前台进程>后台进程）
③I/O型进程>计算型进程。

**高响应比优先调度算法**
主要用于作业调度，是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑了每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备队列中每个作业的响应比，从中选出响应比最高的作业投入运行。
响应比的变化规律可描述为：
响应比Rp = (等待时间+要求服务时间)/要求服务时间
根据公式可知：
①作业的等待时间相同时，要求服务时间约旦，响应比越高，有利于短作业。
②要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。
③对于长作业，作业的响应比可以随等待时间的增加而提高，等待时间足够长时，其响应比便可升到很高，从而可以获得处理机，不会饿死。

**时间片轮转调度算法**
时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中的第一个进程执行，即先来先服务的原则，但是仅能运行一个时间片。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被抢占）处理机给下一个就绪的进程，而被抢占的进程返回到就绪队列的末尾重新排队，等候再次运行。
在时间片轮转的调度算法中，时间片的大小对系统性能有很大影响。如果时间片足够大，以至于所以进程都能在一个事件内执行完毕，则时间片轮转调度算法就退化成FCFS算法。如果时间片很小，则处理机将在进程间过于频繁地切换，使得处理机开销增大，而真正用于运行用户进程的时间将减少。因此，时间片的选择要适当，可以根据系统响应时间、就绪队列中的进程数目和系统的处理能力等决定。

**多级反馈队列调度算法**
多级反馈队列调度算法是时间片轮转算法和优先级调度算法的综合与发展。通过动态调整进程优先级和时间片的大小，多级反馈队列调度算法可以兼顾多方面的系统目标。例如，为了提高系统吞吐量和缩短平均周转时间而照顾短进程；为了获得较好的I/O设备利用率和缩短响应时间而照顾I/O型进程；同时，也不必实现估计进程的执行时间。

### 2. C++ 中 线程同步的方式

#### 2.1 Mutex

可以直接使用 也可以配合 `std::lock_guard` 自动释放锁，其原理是：声明一个局部的lock_guard对象，在其构造函数中进行加锁，在其析构函数中进行解锁。最终的结果就是：在定义该局部对象的时候加锁（调用构造函数），出了该对象作用域的时候解锁（调用析构函数）。

```c++
#include <iostream>
#include <thread>
#include <Windows.h>
#include<mutex>
using namespace std;
mutex mut; \// 声明一个锁
int share = 0;
void thread1()
{
    while(share<20)
    {
        mut.lock();   //将互斥锁进行lock
        share++;
        cout << "this is thread1! share is " << share << endl;
        Sleep(100);
        mut.unlock();  //unlock 解开互斥锁
    }
}
void thread2()
{
    while (share < 20)
    {
        mut.lock();   //将互斥锁进行lock
        share++;
        cout << "this is thread2! share is " << share << endl;
        Sleep(100);
        mut.unlock();  //unlock 解开互斥锁
    }
}

void thread1()
{
    while(share<20)
    {
        std::lock_guard<std::mutex> mtx_locker(mut);  //用lock_guard实现互斥锁
        if(share>=20)
            break;
        share++;
        cout << "this is thread1! share is " << share << endl;
        Sleep(100);
    }
}
void thread2()
{
    while (share < 20)
    {
            std::lock_guard<std::mutex> mtx_locker(mut);  //用lock_guard实现互斥锁
            if (share >= 20)
                break;
            share++;
            cout << "this is thread2! share is " << share << endl;
            Sleep(100);
    }
}


int main()
{
    thread task1(thread1); 
    thread task2(thread2); 
    task1.join();
    task2.join();
    cout << "main thread!" << endl;
}   

```

#### 2.2 临界区

**临界区 (Critical Section) 是一段独占对某些共享资源访问的代码，在任意时刻只允许一个线程对共享资源进行访问** 如果有多个线程试图同时访问临界区，那么在有一个线程进入后其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的。

**如何使用 **

- 定义 **CRITICAL_SECTION类型的变量** 
- 使用 InitializeCriticalSection 进行初始化
- EnterCriticalSection 进入临界区
- LeaveCriticalSection 退出临界区
- CRITICAL_SECTION 释放临界区

```c++
#include <iostream>
#include <thread>
#include <windows.h>
#include<mutex>
using namespace std;
CRITICAL_SECTION Critical; //定义临界区句柄
int share = 0;
void thread1()
{
    while(share<20)
    {
        EnterCriticalSection(&Critical);
        if(share>=20)
            break;
        share++;
        cout << "this is thread1! share is " << share << endl;
        Sleep(100);
        LeaveCriticalSection(&Critical);
    }
}
void thread2()
{
    while (share < 20)
    {
        EnterCriticalSection(&Critical);
        if (share >= 20)
            break;
        share++;
        cout << "this is thread2! share is " << share << endl;
        Sleep(100);
        LeaveCriticalSection(&Critical);
    }
}

int main()
{
    InitializeCriticalSection(&Critical); //初始化临界区对象
    thread task1(thread1); 
    thread task2(thread2); 
    task1.join();
    task2.join();
    cout << "main thread!" << endl;
}   

```

#### 2.3 信号量 Semphore

```c++
#include <iostream>
#include <thread>
#include <windows.h>
#include<mutex>
using namespace std;
HANDLE hSemaphore; //定义信号量句柄
int share = 0;
void thread1()
{
    while(share<20)
    {
        WaitForSingleObject(hSemaphore, INFINITE); //等待信号量为有信号状态
        if(share>=20)
            break;
        share++;
        cout << "this is thread1! share is " << share << endl;
        Sleep(100);
        ReleaseSemaphore(hSemaphore, 1, nullptr);  //释放信号量
    }
}
void thread2()
{
    while (share < 20)
    {
        WaitForSingleObject(hSemaphore, INFINITE); //等待信号量为有信号状态
        if (share >= 20)
            break;
        share++;
        cout << "this is thread2! share is " << share << endl;
        Sleep(100);
        ReleaseSemaphore(hSemaphore, 1, nullptr); //释放信号量
    }
}

int main()
{
    hSemaphore = CreateSemaphore(NULL, 1, 20, "semaphore"); //创建信号量
    thread task1(thread1); 
    thread task2(thread2); 
    task1.join();
    task2.join();
    cout << "main thread!" << endl;
}   

```

#### 2.4 条件变量

在C++11中，我们可以使用条件变量（condition_variable）实现多个线程间的同步操作；当条件不满足时，相关线程被一直阻塞，直到某种条件出现，这些线程才会被唤醒。 **和互斥体的区别就是 可以使得线程按照顺序进行操作！！！！！**

![500](https://img2020.cnblogs.com/blog/2121442/202011/2121442-20201119221924360-1504814913.png)

![700](https://s2.loli.net/2024/08/25/vMandTecolqDtAm.png)

wait ： 前置条件不满足 则 阻塞 
notify ： 前置条件满足 则 通知线程进行执行


**wait**

wait()函数可使得当前线程阻塞，直至条件变量唤醒、或是虚假唤醒。一般代码里为了避免虚假唤醒，会采用while()循环遍历条件的方式。

阻塞该线程时，该函数会自动解锁，允许其他线程执行。一旦得到notify唤醒，该函数取消阻塞并获取锁，然后函数返回，一般为了避免虚假唤醒，会用wile循环判断条件，若为该情况，则函数返回至whie循环条件处。 **使用模板参数 Predicate 防止虚假唤醒**

wait_for()函数导致当前线程阻塞直至**条件变量被通知**、或者**虚假唤醒发生**，或者**超时返回**。相比于wait函数，此函数多了一个超时判断。


![700](https://s2.loli.net/2024/08/25/VRwlABihmYoW4zu.png)


**notify_one/all**

notify_one函数，唤醒阻塞的线程之一。若无线程在等待，则该函数不执行任何操作，若线程超过一个，无法指定选择哪个线程
notify_all函数，唤醒所有阻塞线程，若五线程等待，则该函数不执行任何操作。线程被全部唤醒，但是只有一个线程可以抢占到锁，拿到锁的线程先执行，后续线程谁先拿到锁，谁先执行，直到全部执行完毕。

```c++
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>

std::queue<int> g_queue;
std::mutex g_mutex;
std::condition_variable g_cv;

void producer() {
    for (int i = 0; i < 10; ++i) {
        std::this_thread::sleep_for(std::chrono::seconds(1));

        std::unique_lock<std::mutex> lock(g_mutex);
        g_queue.push(i);

        std::cout << "Producer: " << i << std::endl;

        // 通知等待中的消费者线程
        g_cv.notify_one();
    }
}

void consumer(int id) {
    for (int i = 0; i < 5; ++i) {
        std::unique_lock<std::mutex> lock(g_mutex);

        // 等待条件满足
        g_cv.wait(lock, [] { return !g_queue.empty(); });

        int value = g_queue.front();
        g_queue.pop();

        std::cout << "Consumer " << id << ": " << value << std::endl;
    }
}

int main() {
    std::thread t1(producer);
    std::thread t2(consumer, 1);
    std::thread t3(consumer, 2);

    t1.join();
    t2.join();
    t3.join();

    return 0;
}

```


#### 2.5 原子变量


原子变量（std::atomic）是C++中用于多线程编程的强大工具之一。它们提供了一种线程安全的方式来访问和修改共享数据，而无需使用显式的互斥锁。本文将介绍std::atomic的基本概念、使用方法、常见应用场景以及示例代码，适合入门级读者。

`std::atomic`提供了对原子操作的支持。
https://blog.csdn.net/qq_46017342/article/details/132838649

- 读取 `load`
- 修改值 `store`
- 其他原子操作

通过指定不同的 memory orders 来控制其对其他非原子对象的访问顺序和可见性，从而实现线程安全


>我们可以看到在执行自增操作的时候，在`xaddl` 指令前多了一个`lock`前缀，而`cpu`对这个`lock`指令的支持就是所谓的底层硬件支持。
 增加这个前缀后，保证了 load-add-store 步骤的不可分割性。

**再具体一点：** cpu在执行任务的时候并不是直接从`内存`中加载数据，而是会先将数据加载到`L1`和`L2` cache中（典型的是两层缓存，甚至可能更多），然后再从cache中读取数据进行运算。 如何同步 状态机内部 不同的 L1 缓存呢？

1. 锁 BUS --- 锁总线。这样就可以防止其他CPU的内存操作。等原子操作结束，释放Bus。但是锁住Bus会导致后续无关内存操作都不能继续
2. 锁 Cache。 现在的硬件基本采用MESI协议（或者MESI变种）维护一致性

我们依然假设只有2个CPU的系统。当CPU0试图执行原子递增操作时。a) CPU0发出"Read Invalidate"消息，其他CPU将原子变量所在的缓存无效，并从Cache返回数据。CPU0将Cache line置成Exclusive状态。然后将该**cache line标记locked**。b) 然后CPU0读取原子变量，修改，最后写入cache line。c) 将cache line置位unlocked。

在步骤a)和c)之间，如果其他CPU（例如CPU1）尝试执行一个原子递增操作，CPU1会发送一个"Read Invalidate"消息，CPU0收到消息后，检查对应的cache line的状态是locked，暂时不回复消息（CPU1会一直等待CPU0回复Invalidate Acknowledge消息）。直到cache line变成unlocked。这样就可以实现原子操作。我们称这种方式为锁cache line。这种实现方式必须要求操作的变量位于一个cache line。


### 3. 生产者和消费者模型 需要注意什么？

1. 选择合适的缓冲区大小
	- 过小 可能导致频繁的阻塞
	- 过大 内存资源浪费
1. 线程之间的同步
2. 减少线程的切换


## Lua

### 1. 只读表

简单来说就是套了一层 proxy ， proxy 想要 修改 内部的东西 必须使用 `__newindex` ，在这里传入一个方法就可以禁止修改。

```lua
function ReadOnlyTable (t)
	local proxy = {}
	local mt = {
	__index = t,
	__newindex = function (t,k,v)
		error("attempt to update a read-only talbe",2)
	end
	}
	setmetatable(proxy,mt)
	return proxy
end
```

### 2. 查改操作

也可以简单的使用 `__newindex`

```lua
local function ReadUpdateOnly (t)
    local proxy = t or {}
    local mt = { 
        __newindex = function (t,k,v) 
	        error("只能初始化时对该表定义",2)
	     end
	}
	setmetatable(proxy,mt)
	return proxy
end
```

### 3. Lua GC

#TODO 

## 图形学

![[面试 - 数学#1. 如何判断一个物体在目标的左还是右]]

### 2. AABB盒 和 OBB 盒

AABB：[Axis](https://so.csdn.net/so/search?q=Axis&spm=1001.2101.3001.7020)-Aligned Bounding Box，轴对齐包围盒;  最小六面体， 需要六个标量，紧密型交叉， 对于不规则几何体冗余空间较大。无法对应旋转，不适合软体
OBB：Oriented Bounding Box，有向包围盒；具有方向的任意性，
包围球：外接球；
OBB比包围球和AABB更加逼近物体，能显著减少包围体的个数，对于相交测试比较复杂。更加逼近物体，可以减少包围体的个数。相交测试比AABB复杂。



## Unity 

### 1. SRP

Unity 有两种光线 ： 内置管线 BRP ， 和 可编辑管线 SRP --- 又可以分为URP 通用渲染管线 和 HDRP  高清渲染管线

SRP的API可以创建自定义的渲染管线。


### 2. 剔除

https://blog.csdn.net/qq_37524903/article/details/138501831
https://www.bilibili.com/video/BV1RKv4ejEYU/?spm_id_from=333.337.search-card.all.click&vd_source=8beb74be6b19124f110600d2ce0f3957

**两种剔除方法：** 
- **静态遮挡剔除** (Static occlusion Culling)  
	- 发生时间 ： 场景构建时进行的
	- 主要是通过 Unity 自带的预处理工具将场景物体分成一些区域，然后计算这些区域之间的遮挡关系。这种方式适用于静态场景和场景中的大部分物体都是静态的情况。静态遮挡剔除的优点是计算量小，不会对游戏运行时的性能造成太大影响。
- **动态遮挡剔除** (Dynamic Occlusion Culling)
	- 发生时间 ： 游戏进行的发生
	- 主要是通过摄像机视野和场景中物体之间的遮挡关系来计算需要渲染的物体。这种方式适用于动态场景和场景中有大量动态物体的情况。动态遮挡剔除的优点是可以适应动态变化的场景，但需要计算量较大，可能会对游戏运行时的性能造成一定影响。

#### 2.1 静态遮挡剔除对象

1. 需要设置两个选项：

- Occluder Static 属于静态遮挡物体，设置后，**可以遮挡其它物体**。  
- Occludee Static 属于静态被遮挡物体，设置后，**可以被其它遮挡物体遮挡，但是不能遮挡其他物体**。

> 小物体 使用被遮挡物体， 大物体被用作遮挡物体

2. 创建Occlusion Area组件

> 在区域内会被分割为较小的单元格(精度较高)， 外部的时被分割为较大的单元格(精度低)
> 如果没有分配，会出现很多细小的单元格，比较耗时

- Window --Rendering–Occlusion Culling 打开遮挡剔除面板
- 创建Occlusion Area组件
	- 选择到Object，再选择Occlusion Areas，最后点击最下面的Occlusion Areas，创建Occlusion Areas
- 当然也可以创建一个空物体，添加组件Occlusion Area，结果和上面步骤一样。
- 选择Bake，点击下方Bake。

**Occlusion Bake 参数**

Smallest Occluder --- 大于这个值会被视为 Occluder， **同时也决定的单元格的大小**
场景内最小遮挡物的尺寸，设得过大会导致剔除成功率下降，过小会导致性能问题。一般默认就好。

Smallest Hole， ---- 用于忽略较小的洞(如木板房子之间的缝隙)
如果场景中有带孔的物体需要能被视线穿透(例如墙上的洞, 房间的门)，那么需要将Smallest Hole设置为小于孔的直径
一般默认即可。

Backface threshold --- 是否忽略物体的背面 (3D 多边形的背面) 推荐设置 100
本参数的引入是为了减少剔除数据大小，另一方面，设置不当会导致剔除错误（可见的物体被剔除了）。因此，暂时请保持默认值100不变。
工作机制是如果PVS产生的某个cell中观察到的阻挡面是backface的比例大于设定值，那么生成的剔除数据中将不会包含这个cell相关内容，从而降低了数据大小。如果运行时camera移动到该cell内，那么剔除查询结果将会是“Undefined”。


**Occlusion Potal** 遮挡入口

如果开放 ，则不会作为 Occluder，常用于门

#### 2.2 动态剔除

1. 在 mesh Render 中开启 Dynamic Occlusion
2. 添加 **Occlusion Potal** 
3. 先择 Bake 点击拷贝 


#### 2.3 总结

1. 静态剔除的物体，无法移动
2. 如果修改了场景，需要重新Bake



### 3. NavMesh

支持动态阻挡

包含部分：
1. 导航网格/ Navigation Mesh  地形数据， 自动构建/烘焙
2. NavMesh Agent 组件。进行寻路的物体
3. Off-Mesh Link , 无法使用可新增走表面来表示的导航接近， 如传送点/沟渠/围栏
4. NavMesh Obstacle 组件， 描述应该避开的障碍物

**地图搭建要点** 

1. Nvaigation 窗口
	1. Object 窗口
		1. Scene Filter 筛选器
		2. Navigation Static 确定静态导航物体
		3. Generate  OffMeshLink 确定连接
		4. Navigation Area 确定区域。不同的 Area 有不同的消耗
		5. Bake
	2. Bake 窗口
		1. Agent Redias 确定烘焙边缘的精确度， 越小表示可以行走的区域越高。
		2. Agent Height 烘焙高度的精确度。 确定是否能通过拱桥拱桥的精确度。
		3. Max Slope ，最大斜坡， 确定斜坡是否可以行走。
		4. Step height , 台阶高度。
		5. Generated Off Mesh Links 确定非网格连接
			1. Drop Height 可以下落的高度
			2. Jump Distance 跳跃的距离
		6. Advance
			1. Voxel ： 立体像素大小
			2. Min Region Area
			3. Height Mesh

[Nav Mesh Agent DOC](https://docs.unity.cn/cn/2023.2/Manual/class-NavMeshAgent.html)
[Off Mesh Link](https://docs.unity.cn/cn/2023.2/Manual/class-OffMeshLink.html)

动态阻挡 [Nav Mesh Obstacle](https://docs.unity.cn/cn/2023.2/Manual/class-NavMeshObstacle.html)
**注意：要取消静态**
勾选 Carve 复选框后，导航网格障碍物会在导航网格中创建一个孔。

#### 显示实时路径

使用 LineRenderer 。 


### 4. 动画混合原理

1. 权重计算：根据动画混合树种的参数计算每个动作的权重
2. 插值，根据计算的权重将不懂动画的骨骼变换进行线性插值

### 5. UI 遮罩

mask 和 rectMask

mask ： GPU 模板测试
rectMasK  cpu算的，使用顶点重构的方式裁剪矩形

### 6. UGUI

#### 6.1 动静分离

**基本原理**
UGUI 使用 **合并Mesh的优化操作，减少 drawCall，** **但是一旦UI动起来了原本的不需要重构的内容也会进行rebuild**，这导致合并 mesh 这种优化操作从好事变为坏事从好事变为坏事。

因此动静分离就是，减少 rebuild 操作，将会动的UI合并，这部分 rebuild 会比较频繁，而对于基本不懂的 UI 则不参与 Mesh 重构。 减少CPU在 rebuild 和 合并时的消耗

### 6.2 如何拆分UI

- 将隐藏的UI界面拆分出来，成为单独运行的界面，只有在需要的时候才进行实例化
- 如果显示的内容较多，可以将2次内容拆分 **（开始显示的内容和之后显示的内容不同的画面）**
- 权衡加载速度和内存，如果拆分的过小，加载和销毁过于频繁，可以不销毁。 **见** [[面试 - 经验#6.3 UI预加载]]

#### 6.3 UI预加载

**预加载的原因**

- UI 实例化的过程，需要将 Prefab 实例化到场景中。**这期间会出现 Mesh 合并 + 组件的初始化 + 渲染初始化 + 图片的加载 + 界面逻辑的初始化过程** 这期间会出现很多CPU资源的消耗。进而导致 卡顿。
- 使用预加载可以让这些初始化操作尽量出现在 游戏时间 之前的等待时间

**如何进行预加载**

1. 在游戏开始之前加载 UI 资源 但是不实例化，**这样 CPU 消耗的重心就是 实例化 和 初始化 上** (LoadAsset)
2. 进一步来说，我们可以 **优化 实例化和初始化** 我们直接在 等待的过程中进行 实例化和初始化，随后隐藏 UI，同理关闭的时候不进行销毁

> 内置的 preload 方法进行预加载， 也可以自己手动

cpu资源的消耗总量不变， 我们只是将它放到用户不在意的地方，而不是集中消耗。 

### 6.4 改变UIGUI图片的颜色或 alpha 后，会导致 mesh 重构和增加 drawcall 吗

1. 修改 **Image** 组件上的Color --- 改变了 **顶点颜色** 会引起 网格的 Rebuild
	- 好处 ： 原本的材质不变， 不会产生 Draw Call
2. UI 默认的 shader 有一个 Tint Color 变量， 正常情况下为 (1,1,1) 同时不会被修改。如果我们用脚本访问 Material，并修改上面的 Tint Color 时， UI 元素 产生的网格信息并没有影响，因此不会进行 mesh 重构，但是由于改变的了材质，会增加一个 DrawCall。

**直接修改 color 会 mesh 重构， 但是不会有 额外的 DrawCall。**
**修改 Material 中的 Color  不会引起 mesh 重构， 到那时会产生额外的 DrawCall**

**优化方案：**

1. 使用自定义材质球，并在UI上进行设置
2. 修改 color 的时候 直接设置这个 自定义材质球的参数，避免 Mesh 重建，(控制渲染过程)

#### 6.5 优化UI展示与关闭

打开的时候需要实例化和初始化， 关闭需要撤销销毁 GameObject。 这些 操作 十分消耗 CPU。 

1. 使用碎片时间进行预加载
2. 在关闭的时候进行隐藏，打开的时候显示
3. 移除屏幕。移除屏幕并不会消耗CPU，但是会减少GPU在这个界面上的消耗。需要的时候重新移入屏幕
4. 打开关闭的收，设置UI界面为其他层级 Layout，使得其排除在相机渲染之外，当需要展示时在设置回UI层级。

2，3，4利用内存换CPU， 关闭的时候，内存不变，但是 CPU 消耗减少。

#### 6.7  UI 图集拼如何优化

1. 减少图集上的碎片空间， **把大图进行拆分，大图和小图穿插**
2. 控制图集大小，标准大小 `1024*1024`
3. 分类拼接， 比如不同界面， 不同功能类图集(背包，大厅，任务等) 链接类(多个界面会使用的)
	- 目的：减少图集大小，减少一次性加载图集数量

#### 6.8 Mask 合批

**mask 只能 和 mask 合批**

1. **mask 本身会产生两个 drawcall， 很消耗性能**
	- 一个时模板缓存产生的
	- 一个时mask 还原模板缓存 产生的

**不能合批的原因** :  会产生一个特殊的材质，材质不同不能合批

**注意点**：

1. 剔除部分会影响深度计算，从而影响合批
2. 剔除部分还会有 drawcall
3. mask 下的 子物体可以正常进行合批
4. mask之间只要满足合批条件， 他们之间的元素也可以进行合批

**rectMask** ： 
1. 本身不占用 drawcall
2. 逻辑： 在 canvas render 中进行，范围内不会渲染

**rectMask 为什么性能好**

1. 本身没有 drawcall， mask 本身就有两次
2. rectmask 对于这笔部分不进行绘制， 而Mask是进行剔除

**rectMask 注意点**

1. 遮罩的部分因为没有进行绘制， 不影响深度计算以及合批
2. 一个 RectMask2D 下的物体不能和另一个 RectMask2D 下的物体进行合批， 但是 一个 RectMask2D 下的可以进行合批
3. RectMask2D 组件的Image之间可以进行合批

### 7 查看自身是否隐藏

activeInHierarchy状态代表物体在场景中的实际的active状态。实际上代表的是物体及其所有祖先物体的activeSelf状态。而activeSelf对应于其在inspector中的checkbox是否被勾选

activeSelf状态代表物体自身的activeSelf状态，所以当物体本身activeSelf为true，而其所有祖先物体的activeSelf状态不全为true时，这个物体的activeInHierarchy状态为false。

## 算法

### 1. 10万个数找到三个最大的

拆分为多个组(可以使用单调队列)，单独找到三个最大的。然后根据每个组的结构再找3个最大的

### 2. A Star

#TODO 

### 3. 红黑树

[[面试 - 算法#红黑树]]

### 4. 最大子数组和

我们用 f(i) 代表以第 i 个数结尾的「连续子数组的最大和」

## 其他 

1）每个结点要么是红的，要么是黑的。  
2）根结点是黑的。  
3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。  
4）如果一个结点是红的，那么它的俩个儿子都是黑的。  
5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。


能保证在最坏情况下，基本的动态几何操作的时间均为O（lgn）