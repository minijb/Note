
**编译的四个阶段** : 预处理, 编译, 汇编, 链接

- 预处理 : 将 # 开头的代码修改为 c代码,  得到另一个 c程序 : .i
- 编译阶段 : 编译器 **cc1** 将 .i 文件 翻译为 .s 文件, 包含汇编语言程序
- 汇编阶段:  **汇编器（as）**  将.s 文件翻译为机器语言,**把这些指令打包成一种叫做可重定位目标程序**,并将结果保存在目标文件 hello.o 中.
- 链接阶段 : **链接器（ld）就负责处理这种合并。结果就得到 hello 文件，它是一个可执行目标文件**（或者简称为**可执行文件**），可以被加载到内存中，由系统执行。

> **重定位**
   1）汇编器生成一个目标模块时从地址0开始生成代码和数据节 ，它并不知道数据和代码最终将放在内存的什么位置，也不知道这个模块引用的任何外部定义的函数或者全局变量的位置。  
   2）链接器在重定位步骤中，合并输入模块并将运行时地址赋给输入模块定义的每个节、符号。当这一步完成时，程序中的每条指令和全局变量才拥有唯一的运行时内存地址。

### 硬件组成

1. 总线 : 通常总线被设计成传送定长的字节块，也就是字（word）
2.  IO设备 : 每个 I/O 设备都通过一个**控制器**或**适配器**与 I/O 总线相连。控制器和适配器之间的区别主要在于它们的封装方式。控制器是 I/O 设备本身或者系统的主印制电路板（通常称作主板）上的芯片组。而适配器则是一块插在主板插槽上的卡。无论如何，它们的功能都是在 I/O 总线和 I/O 设备之间传递信息。

![IO](https://hansimov.gitbook.io/~gitbook/image?url=https%3A%2F%2F4154149387-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-MHt_spaxGgCbp2POnfq%252F-MHzautgnqCcwmhp1v0t%252F-MHzbJTPxV8WF5Cpigw-%252F01-04%2520system%2520hardwares.png%3Falt%3Dmedia%26token%3D78949ed7-8d53-4392-b21d-e6123cd2dc50&width=768&dpr=4&quality=100&sign=655fc934&sv=1)
3. **主存**是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组**动态随机存取存储器**（DRAM）芯片组成的
4. **中央处理单元**（CPU），简称**处理器**，是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或**寄存器**），称为**程序计数器**（PC）。在任何时刻，PC 都指向主存中的某条机器语言指令（即含有该条指令的地址）

这样的简单操作并不多，它们围绕着主存、**寄存器文件**（register file）和**算术/逻辑单元**（ALU）进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。ALU 计算新的数据和地址值。下面是一些简单操作的例子，CPU 在指令的要求下可能会执行这些操作。

- **加载**从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容。
- **存储**从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原 来的内容。
- **操作**把两个寄存器的内容复制到 ALU，ALU 对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容。
- **跳转**从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，以覆盖 PC 中原来的值。

执行 hello 程序的过程

1. shell 将 输入存储到寄存器, 然后放入主存中
2. 敲入回车的时候， 然后 shell 执行一系列指令来加载可执行的 hello 文件，**这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存**。数据包括最终会被输出的字符串 “hello, world\n”。(**DMA** 数据可以不通过处理器而直接从磁盘到达主存)
3. 一旦加载完毕, 会将 字符串复制到 cpu 中, 然后输出到屏幕

为了处理主存和寄存器之间速度差异过大的问题,  实现了告诉缓存存储器


![存储](https://hansimov.gitbook.io/~gitbook/image?url=https%3A%2F%2F4154149387-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-MHt_spaxGgCbp2POnfq%252F-MHzhX2vrq6mFP3tN9EU%252F-MHzi1Edm9hUsnQdAkkL%252F01-09%2520%25E4%25B8%2580%25E4%25B8%25AA%25E5%25AD%2598%25E5%2582%25A8%25E5%2599%25A8%25E5%25B1%2582%25E6%25AC%25A1%25E7%25BB%2593%25E6%259E%2584%25E7%259A%2584%25E7%25A4%25BA%25E4%25BE%258B.png%3Falt%3Dmedia%26token%3Dafb8208e-17dc-475f-9f61-acf0bd0ca891&width=768&dpr=1&quality=100&sign=a6c43c29&sv=1)
L1 是 L2 的高速缓存，L2 是 L3 的高速缓存，L3 是主存的高速缓存，而主存又是磁盘的高速缓存。在某些具有分布式文件系统的网络系统中

- L1 缓存是距离处理器核心最近的缓存层，用于存储最常用的数据和指令
- L2 缓存位于 L1 缓存和主内存之间，用于存储更多的数据和指令，以便在 L1 缓存未命中时提供更多的备份
- L3 缓存是位于处理器核心之间的共享缓存，多个处理器核心可以共享相同的 L3 缓存。这有助于减少核心之间的数据传输时间

### 操作系统管理的硬件

![操作系统](https://hansimov.gitbook.io/~gitbook/image?url=https%3A%2F%2F4154149387-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-MHt_spaxGgCbp2POnfq%252F-MHzi6gd3YrHlZtNiGnn%252F-MHzibk5fcFFoAm7QN5W%252F01-11%2520%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E6%258F%2590%25E4%25BE%259B%25E7%259A%2584%25E6%258A%25BD%25E8%25B1%25A1%25E8%25A1%25A8%25E7%25A4%25BA.png%3Falt%3Dmedia%26token%3D27d4ecf7-428d-43ca-a754-c841c327f065&width=768&dpr=1&quality=100&sign=714a8a5c&sv=1)

**进程**是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而**并发运行**，则是说一个进程的指令和另一个进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的。

操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是**上下文**，包括许多信息，比如 PC 和寄存器文件的当前值，以及主存的内容。

从一个进程到另一个进程的转换是由操作系统**内核**（kernel）管理的。内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的**系统调用**（system call）指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。

![1](https://hansimov.gitbook.io/~gitbook/image?url=https%3A%2F%2F4154149387-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-MHt_spaxGgCbp2POnfq%252F-MHzietxOnE2XCBTZHJ7%252F-MHziqrI26zhGJA9_NLL%252F01-12%2520%25E8%25BF%259B%25E7%25A8%258B%25E7%259A%2584%25E4%25B8%258A%25E4%25B8%258B%25E6%2596%2587%25E5%2588%2587%25E6%258D%25A2.png%3Falt%3Dmedia%26token%3D5df4420b-e3c7-46ca-8192-ba207aa49f15&width=768&dpr=1&quality=100&sign=fb7e9c21&sv=1)
但是在现代系统中，一个进程实际上可以由多个称为**线程**的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据.

**虚拟内存**

![虚拟内存](https://hansimov.gitbook.io/~gitbook/image?url=https%3A%2F%2F4154149387-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-MHt_spaxGgCbp2POnfq%252F-MHzietxOnE2XCBTZHJ7%252F-MHzj3WC193cZbjm8s4A%252F01-13%2520%25E8%25BF%259B%25E7%25A8%258B%25E7%259A%2584%25E8%2599%259A%25E6%258B%259F%25E5%259C%25B0%25E5%259D%2580%25E7%25A9%25BA%25E9%2597%25B4.png%3Falt%3Dmedia%26token%3De75f285a-1895-46f5-83fd-e8857326e5f9&width=768&dpr=1&quality=100&sign=627e4347&sv=1)

- **程序代码和数据** 对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 **C 全局变量相对**应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的，在示例中就是可执行文件 hello。在第 7 章我们研究链接和加载时，你会学习更多有关地址空间的内容。
- **堆** 代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小，与此不同，当调用像 malloc 和 free 这样的 C 标准库函数时，堆可以在运行时动态地扩展和收缩。在第 9 章学习管理虚拟内存时，我们将更详细地研究堆。
- **共享库**大约在地址空间的中间部分是一块用来存放像 C 标准库和数学库这样的共享库的代码和数据的区域。共享库的概念非常强大，也相当难懂。在第 7 章介绍动态链接时，将学习共享库是如何工作的。
- **栈**位于用户虚拟地址空间顶部的是**用户栈**，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。特别地，每次我们调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩。在第 3 章中将学习编译器是如何使用栈的。
- **内核虚拟内存**地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，它们必须调用内核来执行这些操作。

![多核处理器](https://hansimov.gitbook.io/~gitbook/image?url=https%3A%2F%2F4154149387-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-MHt_spaxGgCbp2POnfq%252F-MHzl0fd6lZg8Hh-AE9H%252F-MI-7jCviAytfKKxpbQG%252F01-17%2520%25E5%25A4%259A%25E6%25A0%25B8%25E5%25A4%2584%25E7%2590%2586%25E5%2599%25A8%25E7%259A%2584%25E7%25BB%2584%25E7%25BB%2587%25E7%25BB%2593%25E6%259E%2584.png%3Falt%3Dmedia%26token%3D268e2b0a-03ce-4e72-92ac-b209f776effe&width=768&dpr=1&quality=100&sign=731d45a8&sv=1)
超线程，有时称为**同时多线程**（simultaneous multi-threading），是一项允
